)
head(rawEmploymentData)
n_distinct(rawEmploymentData$STATEFIP)
unique(rawEmploymentData$STATEFIP)
# Keep only states
employmentData1 <- rawEmploymentData %>%
filter(!STATEFIP %in% c("037", "51000"))
n_distinct(employmentData1$STATEFIP)
# Aggregate monthly unemployment rates into annual
annualEmploymentData <- employmentData1 %>%
group_by(STATE, STATEFIP, YEAR) %>%
summarise(
UNEMPLOYMENTRATE = mean(UNEMPLOYMENTRATE, na.rm = TRUE),
) %>%
ungroup()
# Get lag unemployment rates
annualEmploymentData <- annualEmploymentData %>%
group_by(STATE) %>%
mutate(lag_unemployment_rate = lag(UNEMPLOYMENTRATE)) %>%
ungroup()
head(annualEmploymentData)
colSums(is.na(annualEmploymentData))
##### Female Median Weekly Wages #####
# Import data
rawFemaleWage <- read_csv("../data/cps_00006.csv", show_col_types = FALSE)
head(rawFemaleWage)
colSums(is.na(rawFemaleWage))
# Filter only for working women, avoiding case where number of hours worked = 0, but wage not 0 etc
rawFemaleWage1 <- rawFemaleWage %>%
filter(WKSWORK1 > 0, INCWAGE > 0)
# Compute median wage for each state-year, weighted by ASECWT
medianWage <- rawFemaleWage1 %>%
mutate(weekly_wage = INCWAGE / WKSWORK1) %>%
group_by(STATEFIP, YEAR) %>%
summarise(
median_weekly_wage = wtd.quantile(weekly_wage, weights = ASECWT, probs = 0.5, na.rm = T)
)
# Get lag weekly median wage
medianWage <- medianWage %>%
group_by(STATEFIP) %>%
mutate(lag_weekly_median_wage = lag(median_weekly_wage)) %>%
ungroup()
head(medianWage)
View(medianWage)
# Import libraries
library(tidyverse)
library(lubridate)
library(readxl)
library(Hmisc) # this one is for computing weighted median wages
##### Unemployment rate #####
# Import data
rawEmploymentData <- read_excel("../data/ststdnsadata.xlsx",
range = "A9:K31596",
col_names = c("STATEFIP", "STATE", "YEAR", "MONTH", "CNIP", "LABORFORCE", "PCT", "EMPLOYED", "EMPLOYMENTRATE", "UNEMPLOYED", "UNEMPLOYMENTRATE")
)
head(rawEmploymentData)
n_distinct(rawEmploymentData$STATEFIP)
unique(rawEmploymentData$STATEFIP)
# Keep only states
employmentData1 <- rawEmploymentData %>%
filter(!STATEFIP %in% c("037", "51000"))
n_distinct(employmentData1$STATEFIP)
# Aggregate monthly unemployment rates into annual
annualEmploymentData <- employmentData1 %>%
group_by(STATE, STATEFIP, YEAR) %>%
summarise(
UNEMPLOYMENTRATE = mean(UNEMPLOYMENTRATE, na.rm = TRUE),
) %>%
ungroup()
# Get lag unemployment rates
annualEmploymentData <- annualEmploymentData %>%
group_by(STATE) %>%
mutate(lag_unemployment_rate = lag(UNEMPLOYMENTRATE)) %>%
ungroup()
head(annualEmploymentData)
colSums(is.na(annualEmploymentData))
##### Female Median Weekly Wages #####
# Import data
rawFemaleWage <- read_csv("../data/cps_00006.csv", show_col_types = FALSE)
head(rawFemaleWage)
colSums(is.na(rawFemaleWage))
# Filter only for working women, avoiding case where number of hours worked = 0, but wage not 0 etc
rawFemaleWage1 <- rawFemaleWage %>%
filter(WKSWORK1 > 0, INCWAGE > 0)
# Compute median wage for each state-year, weighted by ASECWT
medianWage <- rawFemaleWage1 %>%
mutate(weekly_wage = INCWAGE / WKSWORK1) %>%
group_by(STATEFIP, YEAR) %>%
summarise(
median_weekly_wage = wtd.quantile(weekly_wage, weights = ASECWT, probs = 0.5, na.rm = T)
)
# Get lag weekly median wage
medianWage <- medianWage %>%
group_by(STATEFIP) %>%
mutate(lag_weekly_median_wage = lag(median_weekly_wage)) %>%
ungroup()
head(medianWage)
# Save data
saveRDS(annualEmploymentData, "../cleaned_data/annualEmployment.rds")
saveRDS(medianWage, "../cleaned_data/medianWage.rds")
# Import packages
library(tidyverse)
library(lubridate)
# Import all cleaned datasets
annualEmployment <- readRDS("../cleaned_data/annualEmployment.rds")
indivCPS <- readRDS("../cleaned_data/indivCPS.rds")
medianWage <- readRDS("../cleaned_data/medianWage.rds")
policyImplementation <- readRDS("../cleaned_data/policyImplementation.rds")
##### Merge CPS with unemployment #####
# Making sure both STATEFIP and YEAR are numeric type
annualEmployment <- annualEmployment %>%
mutate(
STATEFIP = as.numeric(STATEFIP),
YEAR = as.numeric(YEAR)
)
head(annualEmployment)
# Pre-merger checks: seeing if there are any potential missing entries
sum(is.na(indivCPS$STATEFIP) | is.na(indivCPS$YEAR))
sum(is.na(annualEmployment$STATEFIP) | is.na(annualEmployment$YEAR))
annualEmployment %>%
count(STATEFIP, YEAR) %>%
filter(n > 1)
anti_join(indivCPS, annualEmployment, by = c("STATEFIP", "YEAR")) %>%
distinct(STATEFIP, YEAR)
# shows observations in annualEmployment that isn't in indivCPS
anti_join(annualEmployment, indivCPS, by = c("STATEFIP", "YEAR")) %>%
distinct(YEAR)
# Only extra entries are the years not accounted for in our project (pre 1982 and post 2011)
# Finally, merge CPS with unemployment data (by YEAR, STATEFIP)
mergedData1 <- indivCPS %>%
left_join(annualEmployment, by = c("STATEFIP", "YEAR"))
head(mergedData1)
##### Merge with median weekly wage #####
# Pre-merger checks
sum(is.na(medianWage$STATEFIP)  | is.na(medianWage$YEAR))
medianWage %>% count(STATEFIP, YEAR) %>% filter(n > 1)
anti_join(mergedData1, medianWage, by=c("STATEFIP","YEAR")) %>% distinct(STATEFIP,YEAR)
anti_join(medianWage, mergedData1, by=c("STATEFIP","YEAR")) %>% distinct(STATEFIP,YEAR)
# Merge
mergedData2 <- mergedData1 %>%
left_join(medianWage, by = c("STATEFIP", "YEAR"))
head(mergedData2)
##### Merge with policy implementation year #####
head(policyImplementation)
# Keeping column names consistent
policyImplementation <- policyImplementation %>%
rename(
STATE = State,
YEAR = year
)
head(policyImplementation)
# Pre-merger checks
sum(is.na(policyImplementation$STATE) | is.na(policyImplementation$YEAR))
sum(is.na(mergedData2$STATE) | is.na(mergedData2$YEAR))
policyImplementation %>% count(STATE, YEAR) %>% filter(n > 1)
anti_join(mergedData2, policyImplementation, by=c("STATE","YEAR")) %>% distinct(STATE,YEAR)
anti_join(policyImplementation, mergedData2, by=c("STATE","YEAR")) %>% distinct(STATE)
# Finally, merge
mergedData3 <- mergedData2 %>%
left_join(policyImplementation, by = c("STATE", "YEAR"))
head(mergedData3)
# Save as RDS
saveRDS(mergedData3, "../cleaned_data/finalmerged.rds")
View(mergedData3)
# Import packages
library(tidyverse)
library(lubridate)
# Import all cleaned datasets
annualEmployment <- readRDS("../cleaned_data/annualEmployment.rds")
indivCPS <- readRDS("../cleaned_data/indivCPS.rds")
medianWage <- readRDS("../cleaned_data/medianWage.rds")
policyImplementation <- readRDS("../cleaned_data/policyImplementation.rds")
##### Merge CPS with unemployment #####
# Making sure both STATEFIP and YEAR are numeric type
annualEmployment <- annualEmployment %>%
mutate(
STATEFIP = as.numeric(STATEFIP),
YEAR = as.numeric(YEAR)
)
head(annualEmployment)
# Pre-merger checks: seeing if there are any potential missing entries
sum(is.na(indivCPS$STATEFIP) | is.na(indivCPS$YEAR))
sum(is.na(annualEmployment$STATEFIP) | is.na(annualEmployment$YEAR))
annualEmployment %>%
count(STATEFIP, YEAR) %>%
filter(n > 1)
anti_join(indivCPS, annualEmployment, by = c("STATEFIP", "YEAR")) %>%
distinct(STATEFIP, YEAR)
# shows observations in annualEmployment that isn't in indivCPS
anti_join(annualEmployment, indivCPS, by = c("STATEFIP", "YEAR")) %>%
distinct(YEAR)
# Only extra entries are the years not accounted for in our project (pre 1982 and post 2011)
# Finally, merge CPS with unemployment data (by YEAR, STATEFIP)
mergedData1 <- indivCPS %>%
left_join(annualEmployment, by = c("STATEFIP", "YEAR"))
head(mergedData1)
##### Merge with median weekly wage #####
# Pre-merger checks
sum(is.na(medianWage$STATEFIP)  | is.na(medianWage$YEAR))
medianWage %>% count(STATEFIP, YEAR) %>% filter(n > 1)
anti_join(mergedData1, medianWage, by=c("STATEFIP","YEAR")) %>% distinct(STATEFIP,YEAR)
anti_join(medianWage, mergedData1, by=c("STATEFIP","YEAR")) %>% distinct(STATEFIP,YEAR)
# Merge
mergedData2 <- mergedData1 %>%
left_join(medianWage, by = c("STATEFIP", "YEAR"))
head(mergedData2)
##### Merge with policy implementation year #####
head(policyImplementation)
# Keeping column names consistent
policyImplementation <- policyImplementation %>%
rename(
STATE = State,
YEAR = year
)
head(policyImplementation)
# Pre-merger checks
sum(is.na(policyImplementation$STATE) | is.na(policyImplementation$YEAR))
sum(is.na(mergedData2$STATE) | is.na(mergedData2$YEAR))
policyImplementation %>% count(STATE, YEAR) %>% filter(n > 1)
anti_join(mergedData2, policyImplementation, by=c("STATE","YEAR")) %>% distinct(STATE,YEAR)
anti_join(policyImplementation, mergedData2, by=c("STATE","YEAR")) %>% distinct(STATE)
# Finally, merge
mergedData3 <- mergedData2 %>%
left_join(policyImplementation, by = c("STATE", "YEAR"))
# For convenience, arrange the columns
mergedData4 <- mergedData3 %>%
select(YEAR, STATEFIP, STATE, ASECWT, ever_treated, treat_start_year, treated,
UNEMPLOYMENTRATE, lag_unemployment_rate, median_weekly_wage, lag_weekly_median_wage,
everything())
head(mergedData4)
View(medianWage)
head(mergedData4)
colSums(is.na(mergedData4))
# Import packages
library(tidyverse)
library(lubridate)
# Import all cleaned datasets
annualEmployment <- readRDS("../cleaned_data/annualEmployment.rds")
indivCPS <- readRDS("../cleaned_data/indivCPS.rds")
medianWage <- readRDS("../cleaned_data/medianWage.rds")
policyImplementation <- readRDS("../cleaned_data/policyImplementation.rds")
##### Merge CPS with unemployment #####
# Making sure both STATEFIP and YEAR are numeric type
annualEmployment <- annualEmployment %>%
mutate(
STATEFIP = as.numeric(STATEFIP),
YEAR = as.numeric(YEAR)
)
head(annualEmployment)
# Pre-merger checks: seeing if there are any potential missing entries
sum(is.na(indivCPS$STATEFIP) | is.na(indivCPS$YEAR))
sum(is.na(annualEmployment$STATEFIP) | is.na(annualEmployment$YEAR))
annualEmployment %>%
count(STATEFIP, YEAR) %>%
filter(n > 1)
anti_join(indivCPS, annualEmployment, by = c("STATEFIP", "YEAR")) %>%
distinct(STATEFIP, YEAR)
# shows observations in annualEmployment that isn't in indivCPS
anti_join(annualEmployment, indivCPS, by = c("STATEFIP", "YEAR")) %>%
distinct(YEAR)
# Only extra entries are the years not accounted for in our project (pre 1982 and post 2011)
# Finally, merge CPS with unemployment data (by YEAR, STATEFIP)
mergedData1 <- indivCPS %>%
left_join(annualEmployment, by = c("STATEFIP", "YEAR"))
head(mergedData1)
##### Merge with median weekly wage #####
# Pre-merger checks
sum(is.na(medianWage$STATEFIP)  | is.na(medianWage$YEAR))
medianWage %>% count(STATEFIP, YEAR) %>% filter(n > 1)
anti_join(mergedData1, medianWage, by=c("STATEFIP","YEAR")) %>% distinct(STATEFIP,YEAR)
anti_join(medianWage, mergedData1, by=c("STATEFIP","YEAR")) %>% distinct(STATEFIP,YEAR)
# Merge
mergedData2 <- mergedData1 %>%
left_join(medianWage, by = c("STATEFIP", "YEAR"))
head(mergedData2)
##### Merge with policy implementation year #####
head(policyImplementation)
# Keeping column names consistent
policyImplementation <- policyImplementation %>%
rename(
STATE = State,
YEAR = year
)
head(policyImplementation)
# Pre-merger checks
sum(is.na(policyImplementation$STATE) | is.na(policyImplementation$YEAR))
sum(is.na(mergedData2$STATE) | is.na(mergedData2$YEAR))
policyImplementation %>% count(STATE, YEAR) %>% filter(n > 1)
anti_join(mergedData2, policyImplementation, by=c("STATE","YEAR")) %>% distinct(STATE,YEAR)
anti_join(policyImplementation, mergedData2, by=c("STATE","YEAR")) %>% distinct(STATE)
# Finally, merge
mergedData3 <- mergedData2 %>%
left_join(policyImplementation, by = c("STATE", "YEAR"))
# For convenience, arrange the columns
mergedData4 <- mergedData3 %>%
select(YEAR, STATEFIP, STATE, ASECWT, ever_treated, treat_start_year, treated,
UNEMPLOYMENTRATE, lag_unemployment_rate, median_weekly_wage, lag_weekly_median_wage,
everything())
head(mergedData4)
colSums(is.na(mergedData4))
# Save as RDS
saveRDS(mergedData4, "../cleaned_data/finalmerged.rds")
# Import packages
library(tidyverse)
library(lubridate)
library(did)
# Import cleaned data
df <- readRDS("../cleaned_data/finalmerged.rds")
# Remove all observations where year > repeal year
df1 <- df %>%
filter(is.na(repeal_year) | YEAR <= repeal_year) %>%
filter(ASECWT != 0) %>%
mutate(RACE = factor(RACE))
colnames(df1)
# For never-treated units, we set treat_start_year to be 0, to be consistent with how the package wants it
df1$treat_start_year[is.na(df1$treat_start_year)] <- 0
# Import packages
library(tidyverse)
library(lubridate)
library(did)
# Import cleaned data
df <- readRDS("../cleaned_data/finalmerged.rds")
# Remove all observations where year > repeal year
df1 <- df %>%
filter(is.na(repeal_year) | YEAR <= repeal_year) %>%
filter(ASECWT != 0)
colnames(df1)
# For never-treated units, we set treat_start_year to be 0, to be consistent with how the package wants it
df1$treat_start_year[is.na(df1$treat_start_year)] <- 0
View(df1)
# Import libraries
library(tidyverse)
library(lubridate)
library(readxl)
library(Hmisc) # this one is for computing weighted median wages
##### Unemployment rate #####
# Import data
rawEmploymentData <- read_excel("../data/ststdnsadata.xlsx",
range = "A9:K31596",
col_names = c("STATEFIP", "STATE", "YEAR", "MONTH", "CNIP", "LABORFORCE", "PCT", "EMPLOYED", "EMPLOYMENTRATE", "UNEMPLOYED", "UNEMPLOYMENTRATE")
)
head(rawEmploymentData)
n_distinct(rawEmploymentData$STATEFIP)
unique(rawEmploymentData$STATEFIP)
# Keep only states
employmentData1 <- rawEmploymentData %>%
filter(!STATEFIP %in% c("037", "51000"))
n_distinct(employmentData1$STATEFIP)
# Aggregate monthly unemployment rates into annual
annualEmploymentData <- employmentData1 %>%
group_by(STATE, STATEFIP, YEAR) %>%
summarise(
UNEMPLOYMENTRATE = mean(UNEMPLOYMENTRATE, na.rm = TRUE),
) %>%
ungroup()
# Get lag unemployment rates
annualEmploymentData <- annualEmploymentData %>%
group_by(STATE) %>%
mutate(lag_unemployment_rate = lag(UNEMPLOYMENTRATE)) %>%
ungroup()
head(annualEmploymentData)
colSums(is.na(annualEmploymentData))
##### Female Median Weekly Wages #####
# Import data
rawFemaleWage <- read_csv("../data/cps_00006.csv", show_col_types = FALSE)
head(rawFemaleWage)
colSums(is.na(rawFemaleWage))
# Filter only for working women, avoiding case where number of hours worked = 0, but wage not 0 etc
rawFemaleWage1 <- rawFemaleWage %>%
filter(WKSWORK1 > 0, INCWAGE > 0)
# Compute median wage for each state-year, weighted by ASECWT
medianWage <- rawFemaleWage1 %>%
mutate(weekly_wage = INCWAGE / WKSWORK1) %>%
group_by(STATEFIP, YEAR) %>%
summarise(
median_weekly_wage = wtd.quantile(weekly_wage, weights = ASECWT, probs = 0.5, na.rm = T)
)
# Get lag weekly median wage
medianWage <- medianWage %>%
group_by(STATEFIP) %>%
mutate(lag_weekly_median_wage = lag(median_weekly_wage)) %>%
ungroup()
head(medianWage)
View(medianWage)
rawFemaleWage <- read_csv("../data/cps_00007.csv", show_col_types = FALSE)
View(rawFemaleWage)
# Import libraries
library(tidyverse)
library(lubridate)
library(readxl)
library(Hmisc) # this one is for computing weighted median wages
##### Unemployment rate #####
# Import data
rawEmploymentData <- read_excel("../data/ststdnsadata.xlsx",
range = "A9:K31596",
col_names = c("STATEFIP", "STATE", "YEAR", "MONTH", "CNIP", "LABORFORCE", "PCT", "EMPLOYED", "EMPLOYMENTRATE", "UNEMPLOYED", "UNEMPLOYMENTRATE")
)
head(rawEmploymentData)
n_distinct(rawEmploymentData$STATEFIP)
unique(rawEmploymentData$STATEFIP)
# Keep only states
employmentData1 <- rawEmploymentData %>%
filter(!STATEFIP %in% c("037", "51000"))
n_distinct(employmentData1$STATEFIP)
# Aggregate monthly unemployment rates into annual
annualEmploymentData <- employmentData1 %>%
group_by(STATE, STATEFIP, YEAR) %>%
summarise(
UNEMPLOYMENTRATE = mean(UNEMPLOYMENTRATE, na.rm = TRUE),
) %>%
ungroup()
# Get lag unemployment rates
annualEmploymentData <- annualEmploymentData %>%
group_by(STATE) %>%
mutate(lag_unemployment_rate = lag(UNEMPLOYMENTRATE)) %>%
ungroup()
head(annualEmploymentData)
colSums(is.na(annualEmploymentData))
##### Female Median Weekly Wages #####
# Import data
rawFemaleWage <- read_csv("../data/cps_00007.csv", show_col_types = FALSE)
head(rawFemaleWage)
colSums(is.na(rawFemaleWage))
# Filter only for working women, avoiding case where number of hours worked = 0, but wage not 0 etc
rawFemaleWage1 <- rawFemaleWage %>%
filter(WKSWORK1 > 0, INCWAGE > 0)
# Compute median wage for each state-year, weighted by ASECWT
medianWage <- rawFemaleWage1 %>%
mutate(weekly_wage = INCWAGE / WKSWORK1) %>%
group_by(STATEFIP, YEAR) %>%
summarise(
median_weekly_wage = wtd.quantile(weekly_wage, weights = ASECWT, probs = 0.5, na.rm = T)
)
# Get lag weekly median wage
medianWage <- medianWage %>%
group_by(STATEFIP) %>%
mutate(lag_weekly_median_wage = lag(median_weekly_wage)) %>%
ungroup()
head(medianWage)
# Save data
#saveRDS(annualEmploymentData, "../cleaned_data/annualEmployment.rds")
saveRDS(medianWage, "../cleaned_data/medianWage.rds")
# Import packages
library(tidyverse)
library(lubridate)
# Import all cleaned datasets
annualEmployment <- readRDS("../cleaned_data/annualEmployment.rds")
indivCPS <- readRDS("../cleaned_data/indivCPS.rds")
medianWage <- readRDS("../cleaned_data/medianWage.rds")
policyImplementation <- readRDS("../cleaned_data/policyImplementation.rds")
##### Merge CPS with unemployment #####
# Making sure both STATEFIP and YEAR are numeric type
annualEmployment <- annualEmployment %>%
mutate(
STATEFIP = as.numeric(STATEFIP),
YEAR = as.numeric(YEAR)
)
head(annualEmployment)
# Pre-merger checks: seeing if there are any potential missing entries
sum(is.na(indivCPS$STATEFIP) | is.na(indivCPS$YEAR))
sum(is.na(annualEmployment$STATEFIP) | is.na(annualEmployment$YEAR))
annualEmployment %>%
count(STATEFIP, YEAR) %>%
filter(n > 1)
anti_join(indivCPS, annualEmployment, by = c("STATEFIP", "YEAR")) %>%
distinct(STATEFIP, YEAR)
# shows observations in annualEmployment that isn't in indivCPS
anti_join(annualEmployment, indivCPS, by = c("STATEFIP", "YEAR")) %>%
distinct(YEAR)
# Only extra entries are the years not accounted for in our project (pre 1982 and post 2011)
# Finally, merge CPS with unemployment data (by YEAR, STATEFIP)
mergedData1 <- indivCPS %>%
left_join(annualEmployment, by = c("STATEFIP", "YEAR"))
head(mergedData1)
##### Merge with median weekly wage #####
# Pre-merger checks
sum(is.na(medianWage$STATEFIP)  | is.na(medianWage$YEAR))
medianWage %>% count(STATEFIP, YEAR) %>% filter(n > 1)
anti_join(mergedData1, medianWage, by=c("STATEFIP","YEAR")) %>% distinct(STATEFIP,YEAR)
anti_join(medianWage, mergedData1, by=c("STATEFIP","YEAR")) %>% distinct(STATEFIP,YEAR)
# Merge
mergedData2 <- mergedData1 %>%
left_join(medianWage, by = c("STATEFIP", "YEAR"))
head(mergedData2)
##### Merge with policy implementation year #####
head(policyImplementation)
# Keeping column names consistent
policyImplementation <- policyImplementation %>%
rename(
STATE = State,
YEAR = year
)
head(policyImplementation)
# Pre-merger checks
sum(is.na(policyImplementation$STATE) | is.na(policyImplementation$YEAR))
sum(is.na(mergedData2$STATE) | is.na(mergedData2$YEAR))
policyImplementation %>% count(STATE, YEAR) %>% filter(n > 1)
anti_join(mergedData2, policyImplementation, by=c("STATE","YEAR")) %>% distinct(STATE,YEAR)
anti_join(policyImplementation, mergedData2, by=c("STATE","YEAR")) %>% distinct(STATE)
# Finally, merge
mergedData3 <- mergedData2 %>%
left_join(policyImplementation, by = c("STATE", "YEAR"))
# For convenience, arrange the columns
mergedData4 <- mergedData3 %>%
select(YEAR, STATEFIP, STATE, ASECWT, ever_treated, treat_start_year, treated,
UNEMPLOYMENTRATE, lag_unemployment_rate, median_weekly_wage, lag_weekly_median_wage,
everything())
head(mergedData4)
colSums(is.na(mergedData4))
# Save as RDS
saveRDS(mergedData4, "../cleaned_data/finalmerged.rds")
View(mergedData4)
